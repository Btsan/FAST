{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DCNN Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataloader\n",
    "\n",
    "Here we use the training dataset from the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from data_reader import LigandDataset\n",
    "\n",
    "batch_size = 64\n",
    "path = os.path.join(\"datasets\",\"postera_protease2_pos_neg_train.hdf5\")\n",
    "#path = \"datasets\\postera_protease2_pos_neg_train.hdf5\"\n",
    "train_data = LigandDataset(path,parse_features=False)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"datasets\",\"postera_protease2_pos_neg_val.hdf5\")\n",
    "val_data = LigandDataset(path,parse_features=False)\n",
    "val_dataloader = DataLoader(\n",
    "    val_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate models\n",
    "\n",
    "Set model instances for use with a cuda device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Cuda: True, Device count: 1, Device selected: cuda \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Killian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from model import CNN3D \n",
    "from data_transformations import VoxelTransform\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "cuda_count = torch.cuda.device_count()\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Use Cuda: {use_cuda}, Device count: {cuda_count}, Device selected: {device} \")\n",
    "\n",
    "data_transform = VoxelTransform(batch_size=batch_size,vol_dim=32,use_cuda=use_cuda)\n",
    "model = CNN3D(num_classes=2,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, RMSprop, lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "#optimizer = Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08)\n",
    "learning_rate = 7e-4\n",
    "decay_iter = 100\n",
    "decay_rate = 0.95\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "optimizer = RMSprop(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=decay_iter, gamma=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training step \n",
    "\n",
    "def train(\n",
    "    dataloader, \n",
    "    data_transform,\n",
    "    model,\n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device,\n",
    "    scheduler=None\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Primary training function.\n",
    "\n",
    "    Args:\n",
    "        dataloader:\n",
    "            An instance of Dataloader using the protease train dataset\n",
    "        data_transform:\n",
    "            A data transformation layers that returns voxels from the dataloader\n",
    "        model:\n",
    "            An instance of Model_3DCNN from model.py\n",
    "        loss_fn:\n",
    "            A torch.nn loss function object\n",
    "        optimizer:\n",
    "            A torch.optim optimizer object\n",
    "        device:\n",
    "            expects \"cpu\" or \"cuda\" as device specification.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    losses: \n",
    "        A list of losses from each batch computation. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize batch data\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    losses = [] \n",
    "    \n",
    "    # model setup\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    vol_dim = data_transform.vol_dim\n",
    "\n",
    "    # check if scheduler\n",
    "    #check_scheduler = \n",
    "\n",
    "    for batch_idx, batch_data in enumerate(dataloader):\n",
    "\n",
    "        # pass inputs and labels to gpu\n",
    "        inputs_cpu, labels_cpu = batch_data\n",
    "        inputs, labels = inputs_cpu.to(device), labels_cpu.to(device)\n",
    "\n",
    "        vol_batch = data_transform(inputs)\n",
    "        pred, _ = model(vol_batch)\n",
    "        loss = loss_fn(pred, labels)\n",
    "        loss_record = loss.cpu().data.item()\n",
    "        losses.append(loss_record)\n",
    "\n",
    "        # backward step \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # check if scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            current = batch_idx*len(inputs)\n",
    "            print(f\"loss: {loss_record:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error:\n",
      " Accuracy: 51.7 %, Avg loss:2.394857 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check validation step\n",
    "\n",
    "from main_train_validate import validate\n",
    "\n",
    "avg_loss, accuracy = validate(\n",
    "val_dataloader, \n",
    "data_transform,\n",
    "model,\n",
    "loss_fn,  \n",
    "device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!\n",
    "\n",
    "We still need to add the model checkpoints to save the model after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'voxelizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Killian\\Documents\\GitHub\\ligand-classifier-3D\\train_demo.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=9'>10</a>\u001b[0m     losses \u001b[39m=\u001b[39m train(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=10'>11</a>\u001b[0m     train_dataloader, \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=11'>12</a>\u001b[0m     voxelizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=12'>13</a>\u001b[0m     gaussian_filter,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=13'>14</a>\u001b[0m     model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=14'>15</a>\u001b[0m     loss_fn, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=15'>16</a>\u001b[0m     optimizer, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=16'>17</a>\u001b[0m     device\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=20'>21</a>\u001b[0m     avg_loss, accuracy \u001b[39m=\u001b[39m validate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=21'>22</a>\u001b[0m     val_dataloader, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=22'>23</a>\u001b[0m     voxelizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=26'>27</a>\u001b[0m     device\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=27'>28</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=29'>30</a>\u001b[0m     checkpoint_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=30'>31</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m\"\u001b[39m: model\u001b[39m.\u001b[39mstate_dict(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=31'>32</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moptimizer_state_dict\u001b[39m\u001b[39m\"\u001b[39m: optimizer\u001b[39m.\u001b[39mstate_dict(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=32'>33</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: losses[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=33'>34</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m: epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Killian/Documents/GitHub/ligand-classifier-3D/train_demo.ipynb#ch0000010?line=34'>35</a>\u001b[0m     }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'voxelizer' is not defined"
     ]
    }
   ],
   "source": [
    "from main_train_validate import train, validate\n",
    "\n",
    "# here we set a model path for saving\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    \n",
    "    \n",
    "    losses = train(\n",
    "    train_dataloader, \n",
    "    voxelizer,\n",
    "    gaussian_filter,\n",
    "    model,\n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device\n",
    "    )\n",
    "\n",
    "\n",
    "    avg_loss, accuracy = validate(\n",
    "    val_dataloader, \n",
    "    voxelizer,\n",
    "    gaussian_filter,\n",
    "    model,\n",
    "    loss_fn,  \n",
    "    device\n",
    "    )\n",
    "\n",
    "    checkpoint_dict = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"loss\": losses[-1],\n",
    "    \"epoch\": epoch+1\n",
    "    }\n",
    "    model_path = \"models\\\\3DCNN_model_\" + \"checkpoint\" + str(epoch+1) + \".pth\"\n",
    "    torch.save(checkpoint_dict, model_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4d6cd8e3a5dabb7ec9cf28238fbf357eb2de72e6eb89ef0910f063500717db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
