{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/wilfong2/.conda/envs/my-rdkit-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from glob import glob\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import DataParallel\n",
    "from torch_geometric.data import DataListLoader\n",
    "from dataset import PosteraDataset\n",
    "from sgcnn_model import PotentialNetParallel, GraphThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import ConcatDataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "dataset_name = 'Postera'\n",
    "batch_size = 8\n",
    "covalent_gather_width = 16\n",
    "non_covalent_gather_width = 12\n",
    "covalent_k =2\n",
    "non_covalent_k = 2\n",
    "#epochs=100 \n",
    "covalent_threshold = 1.5\n",
    "non_covalent_threshold = 4.5\n",
    "lr = 0.001\n",
    "checkpoint = True\n",
    "checkpoint_dir = 'g/g20/wilfong2/DSSI/sgcnn/new'\n",
    "num_workers=8\n",
    "train_data = 'postera_protease2_pos_neg_train.hdf5'\n",
    "val_data = 'postera_protease2_pos_neg_val.hdf5'\n",
    "use_docking = False\n",
    "feature_size=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(int(0))\n",
    "\n",
    "def collate_fn_none_filter(batch):\n",
    "    return [x for x in batch if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (PotentialNetParallel(\n",
    "    in_channels=feature_size,\n",
    "    out_channels=1,\n",
    "    non_covalent_gather_width=non_covalent_gather_width,\n",
    "    covalent_gather_width=covalent_gather_width,\n",
    "    covalent_k=covalent_k,\n",
    "    non_covalent_k=non_covalent_k,\n",
    "    covalent_neighbor_threshold=covalent_threshold,\n",
    "    non_covalent_neighbor_threshold=non_covalent_threshold, device_ids=None)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "def train(epoch):\n",
    "    print('\\nEpoch : %d'%epoch)\n",
    "    \"\"\"\n",
    "    input args\n",
    "    \n",
    "    loss: loss function \n",
    "    dataloader: \n",
    "    device: cuda or cpu \n",
    "    \"\"\"\n",
    "    bs = batch_size # set up batch size for training & val\n",
    "    #loss = []\n",
    "    train_dataset = []\n",
    "    path = os.path.join(\"postera_protease2_pos_neg_train.hdf5\")\n",
    "    train_dataset.append(PosteraDataset(path, features=False))\n",
    "    #for data in train_data:\n",
    "        #train_dataset.append(PosteraDataset(data)) # using dataset.py to prepare data\n",
    "    #for data in args.val_data:\n",
    "        #val_dataset.append(PosteraDataset(data)) # dataset.py to prepare validation data\n",
    "    train_dataloader = DataListLoader(train_dataset,batch_size=bs, shuffle=False, worker_init_fn=worker_init_fn) # laoding data\n",
    "    # can add drop_last=True in the instance of shuffling dataset\n",
    "     #val_dataloader = DataListLoader(val_dataset, batch_size=bs, shuffle=False, worker_init_fn=worker_init_fn) # load val data\n",
    "    model = (PotentialNetParallel(\n",
    "        in_channels=feature_size,\n",
    "        out_channels=1,\n",
    "        non_covalent_gather_width=non_covalent_gather_width,\n",
    "        covalent_k=covalent_k,\n",
    "        non_covalent_k=non_covalent_k,\n",
    "        covalent_neighbor_threshold=covalent_threshold,\n",
    "        non_covalent_neighbor_threshold=non_covalent_threshold, device_ids=None)).float()\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer=optim.SGD(model.parameters(), lr=0.001,momentum=0.9)\n",
    "    #loss_fn = nn.CrossEntropyLoss() # loss fucntion\n",
    "    #optimizer=optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # might need to add momentum?\n",
    "    \n",
    "    #print('\\nEpoch : d%'%epoch)\n",
    "    \n",
    "    running_loss=0\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = [x for x in batch if x is not None]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = [x[2] for x in batch]\n",
    "        y_ = model(data)\n",
    "        y = torch.cat([x[2].y for x in batch])\n",
    "        \n",
    "        loss = criterion(y.float(), y_cpu().float())\n",
    "        losses.append(loss.cpu().data.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "      \n",
    "        train_loss=running_loss/len(trainloader)\n",
    "        accu=100.*correct/total\n",
    "\n",
    "        train_accu.append(accu)\n",
    "        train_losses.append(train_loss)\n",
    "        print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))\n",
    "\n",
    "    # calculate loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g20/wilfong2/.conda/envs/my-rdkit-env/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataListLoader' is deprecated, use 'loader.DataListLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     52\u001b[0m data \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m---> 53\u001b[0m y_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39my \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y\u001b[38;5;241m.\u001b[39mfloat(), y_cpu()\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m~/.conda/envs/my-rdkit-env/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/DSSI/sgcnn/new/sgcnn_model.py:255\u001b[0m, in \u001b[0;36mPotentialNetParallel.forward\u001b[0;34m(self, data, return_hidden_feature)\u001b[0m\n\u001b[1;32m    252\u001b[0m     data\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# make sure that we have undirected graph\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_undirected(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m):\n\u001b[1;32m    256\u001b[0m     data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m to_undirected(data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# make sure that nodes can propagate messages to themselves\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'edge_index'"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1,epochs+1):\n",
    "    train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
